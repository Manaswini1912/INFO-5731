{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manaswini1912/INFO-5731/blob/main/Kodela_Manaswini_Exercise_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 5**\n",
        "\n",
        "**This exercise aims to provide a comprehensive learning experience in text analysis and machine learning techniques, focusing on both text classification and clustering tasks.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Please use the text corpus you collected in your last in-class-exercise for this exercise. Perform the following tasks***.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission, and no requests will be answered. Manage your time accordingly.**\n"
      ],
      "metadata": {
        "id": "TU-pLW33lpcS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## **Question 1 (20 Points)**\n",
        "\n",
        "The purpose of the question is to practice different machine learning algorithms for **text classification** as well as the performance evaluation. In addition, you are requried to conduct **10 fold cross validation** (https://scikit-learn.org/stable/modules/cross_validation.html) in the training.\n",
        "\n",
        "\n",
        "\n",
        "The dataset can be download from canvas. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Algorithms:**\n",
        "\n",
        "*   MultinominalNB\n",
        "*   SVM\n",
        "*   KNN\n",
        "*   Decision tree\n",
        "*   Random Forest\n",
        "*   XGBoost\n",
        "*   Word2Vec\n",
        "*   BERT\n",
        "\n",
        "**Evaluation measurement:**\n",
        "\n",
        "\n",
        "*   Accuracy\n",
        "*   Recall\n",
        "*   Precison\n",
        "*   F-1 score\n"
      ],
      "metadata": {
        "id": "loi8Sh7UE6ha"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VAZj4PHB70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aaefbf6-e481-4dcc-c332-11d6ca50a963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MultinomialNB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training SVM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training KNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Decision Tree\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training XGBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation Results:\n",
            "MultinomialNB\n",
            "Accuracy: 0.5217\n",
            "Precision: 0.2723\n",
            "Recall: 0.5217\n",
            "F1 Score: 0.3578\n",
            "SVM\n",
            "Accuracy: 0.5217\n",
            "Precision: 0.2723\n",
            "Recall: 0.5217\n",
            "F1 Score: 0.3578\n",
            "KNN\n",
            "Accuracy: 0.4945\n",
            "Precision: 0.2452\n",
            "Recall: 0.4945\n",
            "F1 Score: 0.3276\n",
            "Decision Tree\n",
            "Accuracy: 0.5217\n",
            "Precision: 0.2723\n",
            "Recall: 0.5217\n",
            "F1 Score: 0.3578\n",
            "Random Forest\n",
            "Accuracy: 0.5217\n",
            "Precision: 0.2723\n",
            "Recall: 0.5217\n",
            "F1 Score: 0.3578\n",
            "XGBoost\n",
            "Accuracy: 0.5217\n",
            "Precision: 0.2723\n",
            "Recall: 0.5217\n",
            "F1 Score: 0.3578\n",
            "\n",
            "Best Model: MultinomialNB\n",
            "\n",
            "Test Set Metrics:\n",
            "Accuracy: 0.4992\n",
            "Precision: 0.4992\n",
            "Recall: 1.0000\n",
            "F1 Score: 0.6659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from gensim.models import Word2Vec\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Load the dataset\n",
        "train_data = pd.read_csv(\"/content/stsa-train.txt\", sep='\\t', header=None, names=['label', 'text'])\n",
        "test_data = pd.read_csv(\"/content/stsa-test.txt\", sep='\\t', header=None, names=['label', 'text'])\n",
        "\n",
        "# Preprocessing\n",
        "train_data['text'] = train_data['text'].astype(str).apply(lambda x: x.lower())\n",
        "test_data['text'] = test_data['text'].astype(str).apply(lambda x: x.lower())\n",
        "\n",
        "# Preprocess target labels\n",
        "train_data['label'] = train_data['label'].str.split(' ', expand=True)[0]  # Extract the label from the string\n",
        "train_data['label'] = train_data['label'].astype(int)  # Convert the label to integer\n",
        "test_data['label'] = test_data['label'].str.split(' ', expand=True)[0]  # Extract the label from the string\n",
        "test_data['label'] = test_data['label'].astype(int)  # Convert the label to integer\n",
        "\n",
        "# Split data into X and y\n",
        "X = train_data['text']\n",
        "y = train_data['label']\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    'MultinomialNB': MultinomialNB(),\n",
        "    'SVM': SVC(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'XGBoost': XGBClassifier()\n",
        "}\n",
        "\n",
        "# Define evaluation metrics\n",
        "metrics = {\n",
        "    'Accuracy': accuracy_score,\n",
        "    'Precision': precision_score,\n",
        "    'Recall': recall_score,\n",
        "    'F1 Score': f1_score\n",
        "}\n",
        "\n",
        "# Perform 10-fold cross-validation on each algorithm\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(\"Training\", model_name)\n",
        "    val_scores = {metric: [] for metric in metrics}\n",
        "    for train_index, val_index in kf.split(X):\n",
        "        X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
        "        y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "        if model_name == 'Word2Vec':\n",
        "            # Train Word2Vec model\n",
        "            w2v_model = Word2Vec(sentences=[text.split() for text in X_train_fold], vector_size=100, window=5, min_count=1, workers=4)\n",
        "            X_train_fold_vec = np.array([np.mean([w2v_model.wv[word] for word in text.split() if word in w2v_model.wv] or [np.zeros(100)], axis=0) for text in X_train_fold])\n",
        "            X_val_fold_vec = np.array([np.mean([w2v_model.wv[word] for word in text.split() if word in w2v_model.wv] or [np.zeros(100)], axis=0) for text in X_val_fold])\n",
        "            model.fit(X_train_fold_vec, y_train_fold)\n",
        "            y_pred = model.predict(X_val_fold_vec)\n",
        "        elif model_name == 'BERT':\n",
        "            # Initialize BERT tokenizer and model\n",
        "            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "            bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "            # Preprocess BERT data\n",
        "            encoded_data_train = tokenizer(X_train_fold.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
        "            encoded_data_val = tokenizer(X_val_fold.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "            # Define labels for BERT\n",
        "            labels_train = torch.tensor(y_train_fold.tolist())\n",
        "            labels_val = torch.tensor(y_val_fold.tolist())\n",
        "\n",
        "            # Define BERT data loader\n",
        "            train_data = torch.utils.data.TensorDataset(encoded_data_train['input_ids'], encoded_data_train['attention_mask'], labels_train)\n",
        "            val_data = torch.utils.data.TensorDataset(encoded_data_val['input_ids'], encoded_data_val['attention_mask'], labels_val)\n",
        "\n",
        "            # Define training parameters\n",
        "            batch_size = 32\n",
        "            train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
        "            val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
        "\n",
        "            # Fine-tune BERT model\n",
        "            optimizer = torch.optim.AdamW(bert_model.parameters(), lr=1e-5)\n",
        "            criterion = torch.nn.CrossEntropyLoss()\n",
        "            for epoch in range(3):\n",
        "                bert_model.train()\n",
        "                for batch in train_loader:\n",
        "                    input_ids, attention_mask, labels = batch\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
        "                    logits = outputs[0]\n",
        "                    loss = criterion(logits, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            bert_model.eval()\n",
        "            with torch.no_grad():\n",
        "                y_pred = []\n",
        "                for batch in val_loader:\n",
        "                    input_ids, attention_mask, labels = batch\n",
        "                    outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
        "                    logits = outputs[0]\n",
        "                    _, predicted = torch.max(logits, 1)\n",
        "                    y_pred.extend(predicted.cpu().numpy())\n",
        "        else:\n",
        "            # Use other classifiers\n",
        "            vectorizer = CountVectorizer().fit(X_train_fold)\n",
        "            X_train_fold_vec = vectorizer.transform(X_train_fold)\n",
        "            X_val_fold_vec = vectorizer.transform(X_val_fold)\n",
        "            model.fit(X_train_fold_vec, y_train_fold)\n",
        "            y_pred = model.predict(X_val_fold_vec)\n",
        "\n",
        "        for metric, score_func in metrics.items():\n",
        "            if metric != 'Accuracy':\n",
        "                score = score_func(y_val_fold, y_pred, average='weighted')  # Change 'binary' to 'weighted'\n",
        "            else:\n",
        "                score = score_func(y_val_fold, y_pred)\n",
        "            val_scores[metric].append(score)\n",
        "\n",
        "    # Compute average scores for each metric\n",
        "    avg_val_scores = {metric: np.mean(scores) for metric, scores in val_scores.items()}\n",
        "    results[model_name] = avg_val_scores\n",
        "\n",
        "# Print validation results\n",
        "print(\"\\nValidation Results:\")\n",
        "for model_name, scores in results.items():\n",
        "    print(model_name)\n",
        "    for metric, score in scores.items():\n",
        "        print(f\"{metric}: {score:.4f}\")\n",
        "\n",
        "# Select the best model based on average validation scores\n",
        "best_model_name = max(results, key=lambda x: results[x]['Accuracy'])\n",
        "best_model = models[best_model_name]  # Get the actual model object\n",
        "\n",
        "print(\"\\nBest Model:\", best_model_name)\n",
        "\n",
        "# Train the best model on the entire training set\n",
        "if best_model_name == 'Word2Vec':\n",
        "    w2v_model = Word2Vec(sentences=[text.split() for text in X], vector_size=100, window=5, min_count=1, workers=4)\n",
        "    X_train_vec = np.array([np.mean([w2v_model.wv[word] for word in text.split() if word in w2v_model.wv] or [np.zeros(100)], axis=0) for text in X])\n",
        "    best_model.fit(X_train_vec, y)\n",
        "elif best_model_name == 'BERT':\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    encoded_data_train = tokenizer(X.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
        "    labels_train = torch.tensor(y.tolist())\n",
        "    train_data = torch.utils.data.TensorDataset(encoded_data_train['input_ids'], encoded_data_train['attention_mask'], labels_train)\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=32)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(bert_model.parameters(), lr=1e-5)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(3):\n",
        "        bert_model.train()\n",
        "        for batch in train_loader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "            optimizer.zero_grad()\n",
        "            outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs[0]\n",
        "            loss = criterion(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "else:\n",
        "    vectorizer = CountVectorizer().fit(X)\n",
        "    X_train_vec = vectorizer.transform(X)\n",
        "    best_model.fit(X_train_vec, y)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "if best_model_name == 'Word2Vec':\n",
        "    X_test_vec = np.array([np.mean([w2v_model.wv[word] for word in text.split() if word in w2v_model.wv] or [np.zeros(100)], axis=0) for text in test_data['text']])\n",
        "    y_pred_test = best_model.predict(X_test_vec)\n",
        "elif best_model_name == 'BERT':\n",
        "    encoded_data_test = tokenizer(test_data['text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
        "    labels_test = torch.tensor(test_data['label'].tolist())\n",
        "    test_data = torch.utils.data.TensorDataset(encoded_data_test['input_ids'], encoded_data_test['attention_mask'], labels_test)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=32)\n",
        "\n",
        "    bert_model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_pred_test = []\n",
        "        for batch in test_loader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "            outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs[0]\n",
        "            _, predicted = torch.max(logits, 1)\n",
        "            y_pred_test.extend(predicted.cpu().numpy())\n",
        "else:\n",
        "    X_test_vec = vectorizer.transform(test_data['text'])\n",
        "    y_pred_test = best_model.predict(X_test_vec)\n",
        "\n",
        "# Evaluate test set metrics\n",
        "test_metrics = {metric: score_func(test_data['label'], y_pred_test) for metric, score_func in metrics.items()}\n",
        "\n",
        "# Print test set metrics\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "for metric, score in test_metrics.items():\n",
        "    print(f\"{metric}: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## **Question 2 (20 Points)**\n",
        "\n",
        "The purpose of the question is to practice different machine learning algorithms for **text clustering**.\n",
        "\n",
        "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
        "(You can also use different text data which you want)\n",
        "\n",
        "**Apply the listed clustering methods to the dataset:**\n",
        "*   K-means\n",
        "*   DBSCAN\n",
        "*   Hierarchical clustering\n",
        "*   Word2Vec\n",
        "*   BERT\n",
        "\n",
        "You can refer to of the codes from  the follwing link below.\n",
        "https://www.kaggle.com/karthik3890/text-clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EoQX5s4O70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdcfe1af-4ea6-4c6c-94e1-810c1822cd9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Reviews  KMeans_Cluster  \\\n",
            "0     I feel so LUCKY to have found this used (phone...               1   \n",
            "1     nice phone, nice up grade from my pantach revu...               2   \n",
            "2                                          Very pleased               2   \n",
            "3     It works good but it goes slow sometimes but i...               2   \n",
            "4     Great phone to replace my lost phone. The only...               1   \n",
            "...                                                 ...             ...   \n",
            "4995  This review is not for the product as you may ...               1   \n",
            "4996  The product was in good structure. I'm still n...               1   \n",
            "4997  The iPhone was fine. It works and is in good c...               1   \n",
            "4998                       Screen cracked really quick.               2   \n",
            "4999  Will never buy anything again. I received it a...               2   \n",
            "\n",
            "      DBSCAN_Cluster  Hierarchical_Cluster  Word2Vec_Cluster  BERT_Cluster  \n",
            "0                 -1                     0                 1             2  \n",
            "1                 -1                     0                 1             2  \n",
            "2                 -1                     0                 0             1  \n",
            "3                 -1                     0                 4             0  \n",
            "4                 -1                     0                 1             0  \n",
            "...              ...                   ...               ...           ...  \n",
            "4995              -1                     0                 1             2  \n",
            "4996              -1                     0                 4             3  \n",
            "4997              -1                     0                 4             2  \n",
            "4998              -1                     0                 0             0  \n",
            "4999              -1                     0                 1             0  \n",
            "\n",
            "[5000 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from gensim.models import Word2Vec\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/Amazon_Unlocked_Mobile.csv\")\n",
        "\n",
        "# Sample the first 5000 rows\n",
        "data = data.head(5000)\n",
        "\n",
        "# Preprocess the text data\n",
        "data['Reviews'] = data['Reviews'].astype(str)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_tfidf = vectorizer.fit_transform(data['Reviews'])\n",
        "\n",
        "# K-means Clustering\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "data['KMeans_Cluster'] = kmeans.fit_predict(X_tfidf)\n",
        "\n",
        "# DBSCAN Clustering\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
        "data['DBSCAN_Cluster'] = dbscan.fit_predict(X_tfidf.toarray())\n",
        "\n",
        "# Hierarchical Clustering\n",
        "agg_cluster = AgglomerativeClustering(n_clusters=5)\n",
        "data['Hierarchical_Cluster'] = agg_cluster.fit_predict(X_tfidf.toarray())\n",
        "\n",
        "# Word2Vec Clustering\n",
        "word2vec_model = Word2Vec(sentences=[text.split() for text in data['Reviews']], vector_size=100, window=5, min_count=1, workers=4)\n",
        "word2vec_features = np.array([np.mean([word2vec_model.wv[word] for word in text.split() if word in word2vec_model.wv] or [np.zeros(100)], axis=0) for text in data['Reviews']])\n",
        "kmeans_word2vec = KMeans(n_clusters=5, random_state=42)\n",
        "data['Word2Vec_Cluster'] = kmeans_word2vec.fit_predict(word2vec_features)\n",
        "\n",
        "# BERT Clustering\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def encode_text(text):\n",
        "    input_ids = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)['input_ids'].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(input_ids)\n",
        "    return outputs.pooler_output.cpu().numpy()\n",
        "\n",
        "bert_features = np.concatenate([encode_text(text) for text in data['Reviews']])\n",
        "kmeans_bert = KMeans(n_clusters=5, random_state=42)\n",
        "data['BERT_Cluster'] = kmeans_bert.fit_predict(bert_features)\n",
        "\n",
        "# Display clustering results\n",
        "print(data[['Reviews', 'KMeans_Cluster', 'DBSCAN_Cluster', 'Hierarchical_Cluster', 'Word2Vec_Cluster', 'BERT_Cluster']])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In one paragraph, please compare the results of K-means, DBSCAN, Hierarchical clustering, Word2Vec, and BERT.**"
      ],
      "metadata": {
        "id": "tRijW2aLGONl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have considered first 5000 samples in teh given dataset, as there were errors popping out that large data cannot be handled and requires more time to execute.\n",
        "The clustering methods analyzed the Amazon mobile reviews to group similar ones together. K-means divided the reviews into clusters based on their content, but some reviews were still mixed together. DBSCAN mostly marked the reviews as noise, meaning they didn't fit well into any specific group. Hierarchical clustering put all reviews into one big group, which may not be very useful. Word2Vec and BERT, which understand the meaning of words, created more diverse clusters, capturing different aspects of the reviews. Overall, Word2Vec and BERT performed a better job of organizing the reviews based on their meaning.\n",
        "\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pIYCj5qyGfSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment.\n",
        "\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CAq0DZWAhU9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The entire exercises and assignments were quite challenging, but they provided a valuable learning experience. Understanding and implementing different machine learning algorithms required careful consideration of various parameters and techniques. Despite the difficulties, I tried my best to comprehend the concepts and perform the required actions. Each algorithm demanded a unique approach and parameter tuning, which helped me deepen my understanding. Overall, while challenging, this assignment was a great practice different clustering methods for text data.\n"
      ],
      "metadata": {
        "id": "OgNjQcyvkg-x"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}